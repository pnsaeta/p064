# Homework 2

## Problem 1

Consider the matrix
\\[
 \mat{B} = \begin{pmatrix}
  1  & 2  & 7 \\\ 
  -4 & 3  & 5 \\\ 
  3  & -8 & 3
\end{pmatrix}
\\]

+ Can you tell by inspection whether $$\mat{B}$$ is invertible? How?
+ Perform a LU decomposition of $$\mat{B}$$ either by hand or by writing your own routine.
+ Use your LU decomposition to solve $$ \mat{B} \vdot \vb{x} = \vb{b}$$ for  
\\[
  \vb{b} = \begin{pmatrix} 3 \\\ 2 \\\ 1 \end{pmatrix}
\\]
Be sure to show the intermediate result $$\vb{y}$$ that solves $$\mat{L}\vdot\vb{y} = \mat{P}\vdot\vb{b}$$.


## Problem 2

Find the eigenvalues and an orthonormal set of basis vectors for either
\\[
    \mat{D} = \begin{pmatrix}
      1 & 0 & 1 & 0 \\\ 
      0 & 1 & 0 & 1 \\\ 
      1 & 0 & 1 & 0 \\\ 
      0 & 1 & 0 & 1
    \end{pmatrix}
    \qqtext{or}
    \mat{F} = \begin{pmatrix}
    1 & 1 & 1 & 1 \\\ 
    1 & 1 & 1 & 1 \\\ 
    1 & 1 & 1 & 1 \\\ 
    1 & 1 & 1 & 1
    \end{pmatrix}
\\]
You should feel free to use a `scipy` routine, but please explain its output in a markdown cell.

## Problem 3

Write a Python function `gauss_jordan` using the basic arrays defined by NumPy to perform Gauss-Jordan elimination on a square matrix. The routine should take in the matrix and return its inverse. It should have an optional parameter that controls whether it uses partial pivoting, so you can compare the numerical stability of the method when it uses pivoting and when it doesn't. Be sure to check that your program is working by multiplying the inverse it produces by the original matrix and comparing to the identity matrix.

## Problem 4

Use your `gauss_jordan` function to investigate the numerical instability of Gauss-Jordan elimination when you don't use pivoting. For test cases, use matrices of pseudorandom numbers generated by a call such as

~~~~ python
from numpy.random import default_rng
rng = default_rng()

rng.uniform(<lower_bound>, <upper_bound>, size=(<dim>, <dim>))

rng.uniform(-5, 5, size=(5,5)) # for example
array([[ 4.23959642,  3.60732447, -0.16149884,  3.6900891 ,  2.65585838],
       [ 1.97695378, -3.09057092, -4.10553997, -4.78785912,  1.44810866],
       [-4.27088306, -4.36821066, -2.14689027, -0.29851331, -4.93396243],
       [-1.99115728, -1.63366415, -3.04232138, -1.73824459,  3.46747273],
       [-4.71288883, -1.94345835, -1.96308442, -1.07039782,  2.43547367]])
~~~~

One way to explore the numerical error of the inverse is to multiply the matrix by its inverse, subtract the identity matrix, and then report some statistic on the elements of the remaining matrix (which would be all zeros if there were not error). Be sure to explain your choice for **figure of merit** (although it is really a figure of *demerit*!).

Prepare a plot showing your figure of merit as a function of matrix dimension when you use pivoting and when you don't. It should make very clear why you need to use pivoting! 